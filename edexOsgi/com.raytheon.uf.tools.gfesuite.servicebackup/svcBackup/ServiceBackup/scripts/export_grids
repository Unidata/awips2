#!/bin/bash

##############################################################################
# Script to export gridded data to the central server
#
#     SOFTWARE HISTORY
#    
#    Date            Ticket#       Engineer       Description
#    ------------    ----------    -----------    --------------------------
#    04/29/13        #1761         dgilling       Remove use of NATIONAL_CENTER,
#                                                 script caller will determine
#                                                 which sites to export.
#    05/16/13        #2009         dgilling       New backup structure: 
#                                                 PRIMARY_SITES go to exportgrids/primary/
#                                                 and all other go to exportgrids/backup/.
#    02/12/15        #4103         dgilling       Refactored to support multiple service
#                                                 backup sites.
#    04/28/15        #4427         dgilling       Refactored to support subdomains of the
#                                                 primary domains.
#    10/24/16        #5951         dgilling       Error checking for copying of temp 
#                                                 file.
#
##############################################################################

if [ ${#AWIPS_HOME} = 0 ]
then
    path_to_script=`readlink -f $0`
    export AWIPS_HOME=$(dirname $(dirname $(dirname $(dirname  $path_to_script))))
fi

# ARGUMENTS 
#         $1 = -c run by cron
#              -g run by grib2.bat (used by SendGridToNDFD)
#              -m run by manual push
#              also determined by EXPORT_GRID
#         $2 = wfo ID.
#
#

. ${AWIPS_HOME}/GFESuite/ServiceBackup/configuration/svcbu.env
source ${AWIPS_HOME}/GFESuite/ServiceBackup/scripts/serviceBackupUtil.sh

SITE=`echo ${2} | tr '[A-Z]' '[a-z]'`
CAPS_SITE=`echo ${2} | tr [a-z] [A-Z]`
export SITE

# Create the log file
configureLogging "svcbu_export_grids" ${SITE}

if [ $# -ne 2 ]
then
   echo "Incorrect number of arguments\nCorrect usage: export_grids [-c|-m|-g] wfo"
   exit 1
fi

manuallockFile=$(getLockFile "exportGrids" ${SITE})
cronLockFile=$(getLockFile "exportGridscron" ${SITE})
lockFile=${manuallockFile}

if [ $1 = "-c" ]
then
   lockFile=${cronLockFile}
fi

#determine if export grid is allowed
#
if [ $EXPORT_GRID -eq 0 ] 
then
   echo "You turned off the export grid option. Check EXPORT_GRID."
   exit 1
elif [ "$1" = "-c" ] && [ $EXPORT_GRID -ne 1 ]
then
   echo "Cannot execute grid export since you have disabled the cron job. Check EXPORT_GRID."
   exit 1
elif [ -z "$EXPORT_GRID" ]
then
   echo "EXPORT_GRID not defined. Export grids failed"
   exit 1
fi

lock_status=$(isOperationInProgress "exportGrids" ${SITE})
if [[ "${lock_status}" = "true" ]]
then
    echo "Cannot export grids for ${CAPS_SITE}.  Export grids process already in progress!  Cron will not run this hour."
    exit 1
fi

markTaskInProgress ${lockFile}

echo "Starting exporting grids..."

#
# If this is a non-wfo/non-rfc site, they may not have an edit area for clipping - handle it
#
if [ -z "$SVCBU_GRIDAREA" ] ; then
   SVCBU_MASK=""
else
   SVCBU_MASK="-m $SVCBU_GRIDAREA"
fi

# Need to create the start and end time arguments for ifpnetCDF
# The start time needs to be 6 hours prior to current time, and end time needs to be 6 hours after the 9th day time.
starttime=`date -d "24 hours ago" +%Y%m%d`_`date -d "24 hours ago" +%H00`
endtime=`date -d "+8 days 6 hours" +%Y%m%d`_`date -d "+8 days 6 hours" +%H00`

echo "Running ifpnetCDF..." 

# Name of the database to use in ifpServer to grab grids from.
# NOTE: SVCBU_DB must be defined in ifps-ccc.env file. Defaults to Official.
if [ -n "${SVCBU_DB}" ]
then
   DB_NAME=${CAPS_SITE}_GRID__${SVCBU_DB}_00000000_0000
else
   DB_NAME=${CAPS_SITE}_GRID__Official_00000000_0000
fi
echo "DB_NAME: ${DB_NAME}"

# use PRIMARY_SITES setting to determine NETCDF_PATH
IFS=',' read -ra PRI_SITES <<< "${PRIMARY_SITES}"
if [ ${#PRI_SITES[@]} -eq 0 ] 
then
   declare -a PRI_SITES=( "${AW_SITE_IDENTIFIER}" )
fi
EXPORT_FOR_PRIMARY=0
for primary_site in "${PRI_SITES[@]}"
do
   primary_site=`echo $primary_site | tr [a-z] [A-Z]`
   if [ "$primary_site" = "${CAPS_SITE}" ]
   then
      EXPORT_FOR_PRIMARY=1
      break
   fi
done

NETCDF_PATH=${GFESUITE_HOME}/exportgrids/primary
export NETCDF_TMP_PATH=/tmp/exportgrids
if [ $EXPORT_FOR_PRIMARY -eq 0 ]
then
   NETCDF_PATH=${GFESUITE_HOME}/exportgrids/backup
fi

if [ ! -d ${NETCDF_TMP_PATH} ]; then
   mkdir -p ${NETCDF_TMP_PATH}
   chmod 777 ${NETCDF_TMP_PATH}
fi

# Implement wx element trimming.
# For this, we'll read from a flat file in ${IFPS_DATA} that will contain list
# of element a site wants to include. We'll also check if the site has 
# $SVCBU_TRIM_ELEMS variable set to 1. We will only do wx element trimming if 
# this variable is set to 1. Otherwise, we'll continue to send all grids.
wxflags=""
if [ "${SVCBU_TRIM_ELEMS}" = "1" ]
then
    # Check if we have the file that has list of elements to trim for.
    if [ -f ${IFPS_DATA}/svcbu_export_elements.${SITE} ]; then
        for elem in `cat ${IFPS_DATA}/svcbu_export_elements.${SITE}`
        do
            wxflags="$wxflags -p ${elem}"
        done
    else
        echo "export_grids was not able to find ${IFPS_DATA}/svcbu_export_elements.${SITE} file."
        echo "Without this file, ifpnetCDF will not know how to trim for needed weather elements."
        echo "ifpnetCDF will run without doing any trimming."
    fi
fi

SUBDOMAIN_STR=$(eval "echo \${SUBDOMAINS_$CAPS_SITE}")
if [ -z "${SUBDOMAIN_STR}" ]
then
    declare -a EXPORT_SITES=( "${CAPS_SITE}" )
    declare -a MASKS=( "${SVCBU_MASK}" )
else
    IFS=',' read -ra EXPORT_SITES <<< "${SUBDOMAIN_STR}"
    echo "Found sub-domains ${EXPORT_SITES[@]} for ${CAPS_SITE}"
    MASKS=()
    for siteid in "${EXPORT_SITES[@]}"
    do
        subdomain=`echo ${siteid} | tr [a-z] [A-Z]`
        if [ -z "$SVCBU_GRIDAREA" ]
        then
            MASKS+=( "" )
        else
            MASKS+=( "-m ${SVCBU_GRIDAREA}_${subdomain}" )
        fi
    done
fi

EXPORT_SUCCESS=1
for (( i=0; i<${#EXPORT_SITES[@]}; i++ ));
do
    DOMAIN_SUCCESS=1
    site_id=${EXPORT_SITES[$i]}
    site_id_lc=`echo ${site_id} | tr '[A-Z]' '[a-z]'`
    mask=${MASKS[$i]}
    echo "Export grids for domain ${site_id} using mask: ${mask}"
    
    # Override output site ID if exporting for subdomain
    IFPNETCDF_FLAGS="-o ${NETCDF_TMP_PATH}/${site_id_lc}Grd.netcdf -h localhost -r ${CDSPORT} -d ${DB_NAME} -k -t ${mask} ${wxflags}"
    if [ "${site_id}" != "${CAPS_SITE}" ]
    then
        IFPNETCDF_FLAGS="${IFPNETCDF_FLAGS} -S ${site_id}"
    fi

    # Starting ifpnetCDF to pack the grids
    ${GFESUITE_BIN}/ifpnetCDF ${IFPNETCDF_FLAGS}
    
    if [ $? -ne 0 ]
    then
        DOMAIN_SUCCESS=0
        if [ "$1" != "-c" ]
        then
            netcdf_error=`grep "Some of the requested time ranges are not in the inventory" $logfile`
            if [ -n "$netcdf_error" ]; then
                DOMAIN_SUCCESS=1
            else
                echo "ifpnetCDF failed for site ${site_id}."
            fi
        fi    
    fi
    
    if [ $DOMAIN_SUCCESS -eq 1 ] 
    then
        echo "Copying ${NETCDF_TMP_PATH}/${site_id_lc}Grd.netcdf to ${NETCDF_PATH}/${site_id_lc}Grd.netcdf"
        cp ${NETCDF_TMP_PATH}/${site_id_lc}Grd.netcdf ${NETCDF_PATH}/${site_id_lc}Grd.netcdf
        if [ $? -ne 0 ]
        then
            echo "Could not copy ${NETCDF_TMP_PATH}/${site_id_lc}Grd.netcdf to ${NETCDF_PATH}/${site_id_lc}Grd.netcdf"
            EXPORT_SUCCESS=0
        fi
    else
        EXPORT_SUCCESS=0
    fi

    if [ -f ${NETCDF_TMP_PATH}/${site_id_lc}Grd.netcdf ]
    then
        echo "Removing ${NETCDF_TMP_PATH}/${site_id_lc}Grd.netcdf"
        rm -f ${NETCDF_TMP_PATH}/${site_id_lc}Grd.netcdf
    fi
done

if [ $EXPORT_SUCCESS -eq 1 ] 
then
    # Completed successfully
    markTaskSuccess ${lockFile}
    echo "All done. Export Gridded data has completed"
    exit 0
else
    markTaskFailed ${lockFile}
    echo "Export Gridded data has completed with some errors."
    exit 1
fi
